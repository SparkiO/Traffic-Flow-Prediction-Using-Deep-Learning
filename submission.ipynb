{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d87a415b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import functools\n",
    "import h5py\n",
    "from keras.models import load_model\n",
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "predictions = []\n",
    "def open_file(file):\n",
    "   with h5py.File(file, 'r') as hf:\n",
    "        #get the data\n",
    "        a_group_key = list(hf.keys())[0]\n",
    "        test = list(hf[a_group_key])\n",
    "\n",
    "\n",
    "\n",
    "        # transform to appropriate numpy array\n",
    "        test = test[0:]\n",
    "        test = np.stack(test, axis=0)\n",
    "        return test\n",
    "\n",
    "TIMESTEPS_X = 13\n",
    "X_Seq = TIMESTEPS_X * 3\n",
    "\n",
    "def data_preprocessing(data, COVID):\n",
    "\n",
    "   #combine dimensions of 288 and 8 as in the CNN paper\n",
    "   def combine_dims(a, i=0, n=1):\n",
    "     \"\"\"\n",
    "     Combines dimensions of numpy array `a`,\n",
    "     starting at index `i`,\n",
    "     and combining `n` dimensions\n",
    "     \"\"\"\n",
    "     s = list(a.shape)\n",
    "     combined = functools.reduce(lambda x,y: x*y, s[i:i+n+1])\n",
    "     return np.reshape(a, s[:i] + [combined] + s[i+n+1:])\n",
    "    \n",
    "    \n",
    "    \n",
    "   print(data.shape)\n",
    "   data = data.swapaxes(0, 4)\n",
    "   print(data.shape)\n",
    "   data = combine_dims(data)\n",
    "\n",
    "   print(data.shape)\n",
    "   #divide the data by 255\n",
    "   data = np.array(data)\n",
    "   data = data / 255.\n",
    "   data = data.swapaxes(0, 3)\n",
    "   print(data.shape)\n",
    "   \n",
    "   return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6023e1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"data/raw/\"\n",
    "CITIES = [\"BERLIN\",\"CHICAGO\",\"ISTANBUL\",\"MELBOURNE\"]\n",
    "#model = load_model('BERLIN.h5', compile=False)\n",
    "city='MELBOURNE'\n",
    "#for city in CITIES:\n",
    "data = open_file('data/raw/{city}/{city}_test_temporal.h5'.format(city=city))\n",
    "part_1 = data[0:25]\n",
    "part_2 = data[25:50]\n",
    "part_3 = data[50:75]\n",
    "part_4 = data[75:100]\n",
    "hf = h5py.File(city+'_1.h5', 'w')\n",
    "hf.create_dataset('dataset_1', data=part_1)\n",
    "hf = h5py.File(city+'_2.h5', 'w')\n",
    "hf.create_dataset('dataset_1', data=part_2)\n",
    "hf = h5py.File(city+'_3.h5', 'w')\n",
    "hf.create_dataset('dataset_1', data=part_3)\n",
    "hf = h5py.File(city+'_4.h5', 'w')\n",
    "hf.create_dataset('dataset_1', data=part_4)\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "158db785",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "PATH = \"data/raw/\"\n",
    "CITIES = [\"BERLIN\",\"CHICAGO\",\"ISTANBUL\",\"MELBOURNE\"]\n",
    "model = load_model('MELBOURNE.h5', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c353bae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in c:\\users\\oli\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.1; however, version 21.2.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\oli\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65dd4520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, to_file=\"model.png\", show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e281e762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 12, 495, 436, 8)\n",
      "(8, 12, 495, 436, 25)\n",
      "(96, 495, 436, 25)\n",
      "(25, 495, 436, 96)\n",
      "(25, 495, 436, 96)\n",
      "25\n",
      "(25, 12, 495, 436, 8)\n",
      "(8, 12, 495, 436, 25)\n",
      "(96, 495, 436, 25)\n",
      "(25, 495, 436, 96)\n",
      "(25, 495, 436, 96)\n",
      "50\n",
      "(25, 12, 495, 436, 8)\n",
      "(8, 12, 495, 436, 25)\n",
      "(96, 495, 436, 25)\n",
      "(25, 495, 436, 96)\n",
      "(25, 495, 436, 96)\n",
      "75\n",
      "(25, 12, 495, 436, 8)\n",
      "(8, 12, 495, 436, 25)\n",
      "(96, 495, 436, 25)\n",
      "(25, 495, 436, 96)\n",
      "(25, 495, 436, 96)\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "#5,10,15,30,45 and 60\n",
    "predictions=[]\n",
    "city='MELBOURNE'\n",
    "#for city in CITIES:\n",
    "for i in range(1,5):\n",
    "    data = open_file('{city}_{i}.h5'.format(city=city, i=i))\n",
    "    x = data_preprocessing(data, True)\n",
    "    print(x.shape)\n",
    "    for hour in x:\n",
    "        hour_prediction = []\n",
    "        prediction = model.predict(np.expand_dims(hour, axis = 0))\n",
    "        prediction = prediction[:, 1:, 6:442, :]\n",
    "\n",
    "        pred_5_10_15 = prediction[0, :, :, :24]\n",
    "        pred_30 = prediction[0, :, :, 40:]\n",
    "\n",
    "        new_data = hour[:, :, :48]\n",
    "        new_data = np.append(new_data, prediction[0], axis = -1)\n",
    "\n",
    "        prediction = model.predict(np.expand_dims(new_data, axis = 0))\n",
    "        prediction = prediction[:, 1:, 6:442, :]\n",
    "\n",
    "        pred_45 = prediction[0, :, :, 16:24]\n",
    "        pred_60 = prediction[0, :, :, 40:]\n",
    "\n",
    "        hour_prediction = np.append(pred_5_10_15, pred_30, axis = -1)\n",
    "        hour_prediction = np.append(hour_prediction, pred_45, axis = -1)\n",
    "        hour_prediction = np.append(hour_prediction, pred_60, axis = -1)\n",
    "        hour_prediction = hour_prediction *255.\n",
    "        predictions.append(hour_prediction)\n",
    "    print(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "26551bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 48, 495, 436)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.array(predictions)\n",
    "predictions = np.moveaxis(predictions, -1, 1)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c6fd2a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100, 48, 495, 436])\n",
      "torch.Size([100, 6, 495, 436, 8])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "`(k, 12 * 8, 495, 436) -> (k, 12, 495, 436, 8)`\n",
    "\"\"\"\n",
    "# `(12, 495, 436, 8) -> (1, 12, 495, 436, 8)`\n",
    "data = torch.unsqueeze(torch.from_numpy(predictions), 0)\n",
    "print(data.shape)\n",
    "num_time_steps = int(predictions.shape[1] / 8)\n",
    "# (k, 12 * 8, 495, 436) -> (k, 12, 8, 495, 436)\n",
    "data = torch.reshape(data, (100, 6, 8, 495, 436))\n",
    "\n",
    "# (k, 12, 8, 495, 436) -> (k, 12, 495, 436, 8)\n",
    "data = torch.moveaxis(data, 2, 4)\n",
    "\n",
    "# `(1, 12, 495, 436, 8) -> (12, 495, 436, 8)`\n",
    "data = torch.squeeze(data, 0)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7e2afa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('MELBOURNE_test_temporal.h5', 'w')\n",
    "hf.create_dataset('dataset_1', data=data, compression=\"gzip\", compression_opts=6)\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9cde8dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = open_file('BERLIN_test_temporal.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "71b57bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 6, 495, 436, 8)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890eb609",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
